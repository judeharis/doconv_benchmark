{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee62275",
   "metadata": {},
   "source": [
    "# Deconvolution Header File Generator\n",
    "\n",
    "This notebook generates `deconv_top.hpp` files with configurable parameters for HLS deconvolution implementations.\n",
    "\n",
    "## Parameters:\n",
    "- **S**: Stride\n",
    "- **K**: Kernel Size\n",
    "- **H**: Input Feature Map Height\n",
    "- **W**: Input Feature Map Width\n",
    "- **CI**: Input Channels\n",
    "- **CO**: Output Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3fe72a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef51f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import List, Tuple, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5842af",
   "metadata": {},
   "source": [
    "## 2. Define Parameter Configuration Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4545489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeconvConfig:\n",
    "    \"\"\"Configuration class for deconvolution parameters\"\"\"\n",
    "        \n",
    "\n",
    "    def __init__(self, K: int, S: int, H: int, W: int, CI: int, CO: int, P: int = None):\n",
    "        self.K = K    # Kernel size\n",
    "        self.S = S    # Stride\n",
    "        self.H = H    # Input height\n",
    "        self.W = W    # Input width\n",
    "        self.CI = CI  # Input channels\n",
    "        self.CO = CO  # Output channels\n",
    "        self.P = P if P is not None else K - S  # Padding (derived if not provided)\n",
    "        \n",
    "    def validate(self) -> bool:\n",
    "        \"\"\"Validate parameter constraints\"\"\"\n",
    "        if self.K <= 0 or self.S <= 0 or self.H <= 0 or self.W <= 0:\n",
    "            return False\n",
    "        if self.CI <= 0 or self.CO <= 0:\n",
    "            return False\n",
    "        if self.P < 0:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"K={self.K}, S={self.S}, H={self.H}, W={self.W}, CI={self.CI}, CO={self.CO}, P={self.P}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06885e44",
   "metadata": {},
   "source": [
    "## 3. Generate Kernel Data Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcf2de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kernel_weights(config: DeconvConfig, pe: int = 1, simd: int = 1) -> str:\n",
    "    \"\"\"Generate kernel weight array in C++ format\"\"\"\n",
    "    \n",
    "    # Calculate array dimensions\n",
    "    outer_dim = (config.CO // pe) * config.K * config.K * (config.CI // simd)\n",
    "    \n",
    "    kernel_lines = []\n",
    "    kernel_lines.append(f\"static TW const  KERNEL[{outer_dim}][{pe}][{simd}] = {{\")\n",
    "    \n",
    "    # Generate weight values\n",
    "    weight_counter = 0\n",
    "    for co_group in range(config.CO // pe):\n",
    "        for k_row in range(config.K):\n",
    "            for k_col in range(config.K):\n",
    "                for ci_group in range(config.CI // simd):\n",
    "                    # Create the inner arrays\n",
    "                    pe_values = []\n",
    "                    for p in range(pe):\n",
    "                        simd_values = []\n",
    "                        for s in range(simd):\n",
    "                            # Generate hex values (can be customized)\n",
    "                            hex_val = f\"0x{weight_counter:02x}\"\n",
    "                            simd_values.append(hex_val)\n",
    "                            weight_counter += 1\n",
    "                        if simd == 1:\n",
    "                            pe_values.append(f\"{{{simd_values[0]},}}\")\n",
    "                        else:\n",
    "                            pe_values.append(f\"{{{','.join(simd_values)},}}\")\n",
    "                    \n",
    "                    if pe == 1:\n",
    "                        line = f\"\\t{{{pe_values[0]}}},\"\n",
    "                    else:\n",
    "                        line = f\"\\t{{{','.join(pe_values)}}},\"\n",
    "                    kernel_lines.append(line)\n",
    "    \n",
    "    kernel_lines.append(\"};\")\n",
    "    # print(\"\\n\".join(kernel_lines))\n",
    "    return \"\\n\".join(kernel_lines)\n",
    "\n",
    "def generate_pe_simd_configs(config: DeconvConfig) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Generate valid PE and SIMD configurations\"\"\"\n",
    "    configs = []\n",
    "    \n",
    "    # Find divisors of CO for PE\n",
    "    pe_options = [i for i in range(1, config.CO + 1) if config.CO % i == 0]\n",
    "    \n",
    "    # Find divisors of CI for SIMD  \n",
    "    simd_options = [i for i in range(1, config.CI + 1) if config.CI % i == 0]\n",
    "    \n",
    "    # Common configurations\n",
    "    for pe in pe_options[:3]:  # Limit to first 3 options\n",
    "        for simd in simd_options[:2]:  # Limit to first 2 options\n",
    "            configs.append((pe, simd))\n",
    "    \n",
    "    return configs if configs else [(1, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc44a0",
   "metadata": {},
   "source": [
    "## 4. Create Header File Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1311aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights_from_csv(weights_path) -> List[int]:\n",
    "    \"\"\"Load flat list of weights from a CSV file. Supports comma/whitespace separated,\n",
    "    decimal or hex (0x..) values. Non-numeric tokens are ignored.\"\"\"\n",
    "    text = Path(weights_path).read_text().strip()\n",
    "    tokens = []\n",
    "    for line in text.splitlines():\n",
    "        parts = [p for p in line.replace(',', ' ').split() if p]\n",
    "        tokens.extend(parts)\n",
    "\n",
    "    values = []\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            v = int(t, 16) if t.lower().startswith(\"0x\") else int(float(t))\n",
    "            values.append(v & 0xFF)  # clamp to 8-bit\n",
    "        except Exception:\n",
    "            # ignore non-numeric tokens (headers, etc.)\n",
    "            continue\n",
    "    return values\n",
    "\n",
    "def generate_kernel_weights(config: DeconvConfig, pe: int = 1, simd: int = 1, weights: List[int] = None) -> str:\n",
    "    \"\"\"Generate kernel weight array in C++ format. If weights is provided, use it;\n",
    "    otherwise generate a simple incremental pattern.\"\"\"\n",
    "    outer_dim = (config.CO // pe) * config.K * config.K * (config.CI // simd)\n",
    "    total_elems = outer_dim * pe * simd\n",
    "\n",
    "    if weights is None or len(weights) == 0:\n",
    "        # fallback: incremental pattern\n",
    "        weights = list(range(total_elems))\n",
    "    else:\n",
    "        # adjust length to match required elements\n",
    "        if len(weights) < total_elems:\n",
    "            weights = weights + [0] * (total_elems - len(weights))\n",
    "        elif len(weights) > total_elems:\n",
    "            weights = weights[:total_elems]\n",
    "\n",
    "    kernel_lines = []\n",
    "    kernel_lines.append(f\"static TW const  KERNEL[{outer_dim}][{pe}][{simd}] = {{\")\n",
    "\n",
    "    idx = 0\n",
    "    for _co_group in range(config.CO // pe):\n",
    "        for _k_row in range(config.K):\n",
    "            for _k_col in range(config.K):\n",
    "                for _ci_group in range(config.CI // simd):\n",
    "                    pe_values = []\n",
    "                    for _p in range(pe):\n",
    "                        simd_values = []\n",
    "                        for _s in range(simd):\n",
    "                            hex_val = f\"0x{(weights[idx] & 0xFF):02x}\"\n",
    "                            simd_values.append(hex_val)\n",
    "                            idx += 1\n",
    "                        if simd == 1:\n",
    "                            pe_values.append(f\"{{{simd_values[0]},}}\")\n",
    "                        else:\n",
    "                            pe_values.append(f\"{{{','.join(simd_values)},}}\")\n",
    "\n",
    "                    if pe == 1:\n",
    "                        line = f\"\\t{{{pe_values[0]}}},\"\n",
    "                    else:\n",
    "                        line = f\"\\t{{{','.join(pe_values)}}},\"\n",
    "                    kernel_lines.append(line)\n",
    "\n",
    "    kernel_lines.append(\"};\")\n",
    "    return \"\\n\".join(kernel_lines)\n",
    "\n",
    "def generate_header_file(config: DeconvConfig, pe_simd_configs: List[Tuple[int, int]], weights_path: str = None) -> str:\n",
    "    \"\"\"Generate complete header file content. If weights_path is provided, load weights\n",
    "    from CSV and pass them to generate_kernel_weights.\"\"\"\n",
    "    header_template = f\"\"\"#ifndef DECONV_TOP_HPP\n",
    "#define DECONV_TOP_HPP\n",
    "\n",
    "#include <ap_int.h>\n",
    "#include <hls_stream.h>\n",
    "#include <hls_vector.h>\n",
    "\n",
    "constexpr unsigned  K = {config.K};\t\t// kernel Size\n",
    "constexpr unsigned  S = {config.S}; \t\t// stride\n",
    "constexpr unsigned  P = {config.P};\t\t// padding\n",
    "constexpr unsigned  H = {config.H};\t\t// IFM height\n",
    "constexpr unsigned  W = {config.W};\t\t// IFM Width\n",
    "constexpr unsigned  CI = {config.CI};\t\t// input channels\n",
    "constexpr unsigned  CO = {config.CO};\t\t// output channels\n",
    "\n",
    "using  TW = ap_uint< 8>;\n",
    "using  TI = ap_uint< 4>;\n",
    "using  TO = ap_uint<16>;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    provided_weights = load_weights_from_csv(weights_path) if weights_path else None\n",
    "\n",
    "    config_sections = []\n",
    "    for i, (pe, simd) in enumerate(pe_simd_configs):\n",
    "        if i == 0:\n",
    "            config_sections.append(\"#if 1\\n\")\n",
    "        else:\n",
    "            config_sections.append(\"#else\\n\")\n",
    "\n",
    "        config_sections.append(f\"constexpr unsigned  PE   = {pe};\\n\")\n",
    "        config_sections.append(f\"constexpr unsigned  SIMD = {simd};\\n\")\n",
    "        config_sections.append(\"\")\n",
    "\n",
    "        kernel_weights = generate_kernel_weights(config, pe, simd, weights=provided_weights)\n",
    "        config_sections.append(kernel_weights)\n",
    "        config_sections.append(\"\")\n",
    "\n",
    "    if len(pe_simd_configs) > 1:\n",
    "        config_sections.append(\"#endif\")\n",
    "\n",
    "    function_decl = \"\"\"\n",
    "void deconv_top(\n",
    "    hls::stream<hls::vector<TI, SIMD>> &src,\n",
    "    hls::stream<hls::vector<TO, PE>>   &dst\n",
    ");\n",
    "\n",
    "#endif\"\"\"\n",
    "\n",
    "    full_content = header_template + \"\\n\".join(config_sections) + function_decl\n",
    "    return full_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013e286",
   "metadata": {},
   "source": [
    "## 5. Generate Multiple Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e77d1f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configurations from /mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/configs/deconv_configs.csv...\n",
      "  Loaded: K=3, S=1, H=3, W=3, CI=1, CO=3, P=2\n",
      "  Loaded: K=3, S=1, H=3, W=3, CI=1, CO=3, P=1\n",
      "Total configurations (including CSV): 2\n",
      "\n",
      "Validating configuration: K=3, S=1, H=3, W=3, CI=1, CO=3, P=2...\n",
      "‚úì Valid: K=3, S=1, H=3, W=3, CI=1, CO=3, P=2\n",
      "Validating configuration: K=3, S=1, H=3, W=3, CI=1, CO=3, P=1...\n",
      "‚úì Valid: K=3, S=1, H=3, W=3, CI=1, CO=3, P=1\n",
      "\\nTotal valid configurations: 2\n",
      "Found weights file for config: K=3, S=1, H=3, W=3, CI=1, CO=3, P=2 -> /mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/exp_data/deconv_3x3_in1_out3_k3_s1_p2_weights.csv\n",
      "Found input file for config: K=3, S=1, H=3, W=3, CI=1, CO=3, P=2 -> /mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/exp_data/deconv_3x3_in1_out3_k3_s1_p2_input.csv\n",
      "Found output file for config: K=3, S=1, H=3, W=3, CI=1, CO=3, P=2 -> /mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/exp_data/deconv_3x3_in1_out3_k3_s1_p2_output.csv\n",
      "Found weights file for config: K=3, S=1, H=3, W=3, CI=1, CO=3, P=1 -> /mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/exp_data/deconv_3x3_in1_out3_k3_s1_p1_weights.csv\n",
      "Found input file for config: K=3, S=1, H=3, W=3, CI=1, CO=3, P=1 -> /mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/exp_data/deconv_3x3_in1_out3_k3_s1_p1_input.csv\n",
      "Found output file for config: K=3, S=1, H=3, W=3, CI=1, CO=3, P=1 -> /mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/exp_data/deconv_3x3_in1_out3_k3_s1_p1_output.csv\n",
      "\n",
      "Total configs with weights files: 2\n",
      "Total config groups: 2\n",
      "Config groups with all files present: 2\n",
      "[{'config': <__main__.DeconvConfig object at 0x76f60413f490>, 'files': {'weights': '/mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/exp_data/deconv_3x3_in1_out3_k3_s1_p2_weights.csv', 'input': '/mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/exp_data/deconv_3x3_in1_out3_k3_s1_p2_input.csv', 'output': '/mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/exp_data/deconv_3x3_in1_out3_k3_s1_p2_output.csv'}, 'all_present': True}, {'config': <__main__.DeconvConfig object at 0x76f60413f4f0>, 'files': {'weights': '/mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/exp_data/deconv_3x3_in1_out3_k3_s1_p1_weights.csv', 'input': '/mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/exp_data/deconv_3x3_in1_out3_k3_s1_p1_input.csv', 'output': '/mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data/exp_data/deconv_3x3_in1_out3_k3_s1_p1_output.csv'}, 'all_present': True}]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define various parameter combinations to generate\n",
    "# configurations = [\n",
    "#     # Original configuration\n",
    "#     DeconvConfig(K=4, S=2, H=6, W=6, CI=1, CO=2),\n",
    "    \n",
    "#     # Small kernel configurations\n",
    "#     DeconvConfig(K=3, S=1, H=8, W=8, CI=2, CO=4),\n",
    "#     DeconvConfig(K=2, S=1, H=4, W=4, CI=1, CO=1),\n",
    "    \n",
    "#     # Large kernel configurations\n",
    "#     DeconvConfig(K=5, S=2, H=10, W=10, CI=4, CO=8),\n",
    "#     DeconvConfig(K=7, S=3, H=14, W=14, CI=3, CO=6),\n",
    "    \n",
    "#     # Different channel configurations\n",
    "#     DeconvConfig(K=4, S=2, H=6, W=6, CI=2, CO=4),\n",
    "#     DeconvConfig(K=4, S=2, H=6, W=6, CI=4, CO=8),\n",
    "    \n",
    "#     # Non-square input sizes\n",
    "#     DeconvConfig(K=3, S=1, H=6, W=12, CI=2, CO=2),\n",
    "#     DeconvConfig(K=4, S=2, H=8, W=4, CI=1, CO=2),\n",
    "# ]\n",
    "configurations=[]\n",
    "\n",
    "# Load configurations from CSV file\n",
    "\n",
    "deconv_data_dir = Path(\"/mnt/Crucial/WorkspaceB/finn_hls/DeConv_benchmark/deconv_data\")\n",
    "config_csv_path = Path(f\"{deconv_data_dir}/configs/deconv_configs.csv\")\n",
    "exp_data_dir = Path(f\"{deconv_data_dir}/exp_data\")\n",
    "\n",
    "if config_csv_path.exists():\n",
    "\n",
    "    print(f\"Loading configurations from {config_csv_path}...\")\n",
    "    with open(config_csv_path, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                config = DeconvConfig(\n",
    "                    K=int(row['kernel_size']),\n",
    "                    S=int(row['stride']),\n",
    "                    H=int(row['input_size']),\n",
    "                    W=int(row['input_size']),\n",
    "                    CI=int(row['in_channels']),\n",
    "                    CO=int(row['out_channels']),\n",
    "                    P=int(row['padding'])\n",
    "                )\n",
    "                configurations.append(config)\n",
    "                print(f\"  Loaded: {config}\")\n",
    "            except (KeyError, ValueError) as e:\n",
    "                print(f\"  Skipping invalid row: {row} - Error: {e}\")\n",
    "    \n",
    "    print(f\"Total configurations (including CSV): {len(configurations)}\\n\")\n",
    "else:\n",
    "    print(f\"No CSV file found at {csv_path}, using predefined configurations only.\\n\")\n",
    "\n",
    "\n",
    "# Validate and filter configurations\n",
    "valid_configs = []\n",
    "for config in configurations:\n",
    "    print(f\"Validating configuration: {config}...\")\n",
    "    if config.validate():\n",
    "        valid_configs.append(config)\n",
    "        print(f\"‚úì Valid: {config}\")\n",
    "    else:\n",
    "        print(f\"‚úó Invalid: {config}\")\n",
    "\n",
    "print(f\"\\\\nTotal valid configurations: {len(valid_configs)}\")\n",
    "\n",
    "weights_files = []\n",
    "config_groups = []\n",
    "\n",
    "# File suffixes to look for\n",
    "suffixes = {\n",
    "    'weights': '_weights.csv',\n",
    "    'input': '_input.csv',\n",
    "    'output': '_output.csv',\n",
    "}\n",
    "\n",
    "for cfg in valid_configs:\n",
    "    base = f\"deconv_{cfg.H}x{cfg.W}_in{cfg.CI}_out{cfg.CO}_k{cfg.K}_s{cfg.S}_p{cfg.P}\"\n",
    "    files = {}\n",
    "    all_present = True\n",
    "\n",
    "    for kind, suff in suffixes.items():\n",
    "        fpath = exp_data_dir / f\"{base}{suff}\"\n",
    "        if fpath.exists():\n",
    "            files[kind] = str(fpath)\n",
    "            if kind == 'weights':\n",
    "                weights_files.append((cfg, str(fpath)))\n",
    "            print(f\"Found {kind} file for config: {cfg} -> {fpath}\")\n",
    "        else:\n",
    "            files[kind] = None\n",
    "            all_present = False\n",
    "            print(f\"No {kind} file for config: {cfg}\")\n",
    "\n",
    "    config_groups.append({\n",
    "        'config': cfg,\n",
    "        'files': files,\n",
    "        'all_present': all_present\n",
    "    })\n",
    "\n",
    "print(f\"\\nTotal configs with weights files: {len(weights_files)}\")\n",
    "print(f\"Total config groups: {len(config_groups)}\")\n",
    "print(f\"Config groups with all files present: {sum(1 for g in config_groups if g['all_present'])}\")\n",
    "\n",
    "print(config_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee4052",
   "metadata": {},
   "source": [
    "## 6. Export Generated Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e53b845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: deconv_top_K3_S1_H3_W3_CI1_CO3_P2.hpp\n",
      "Selector header generated: generated_configs/deconv_top.hpp\n",
      "Generated: deconv_top_K3_S1_H3_W3_CI1_CO3_P1.hpp\n",
      "Selector header generated: generated_configs/deconv_top.hpp\n",
      "\\nüìÅ All files saved to: /mnt/Crucial/WorkspaceB/finn_hls/DeConv_hls_benchmark/generated_configs\n",
      "üìä Total files generated: 2\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"generated_configs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "generated_files = []\n",
    "\n",
    "# Generate header files for each configuration\n",
    "for i, de_config in enumerate(config_groups):\n",
    "    config = de_config['config']\n",
    "    weights_file = de_config['files']['weights']\n",
    "    # Generate PE/SIMD configurations\n",
    "    pe_simd_configs = generate_pe_simd_configs(config)\n",
    "    \n",
    "    # Generate header content and ensure padding is part of the filename\n",
    "    header_content = generate_header_file(config, pe_simd_configs, weights_path=weights_file)\n",
    "    filename = f\"deconv_top_K{config.K}_S{config.S}_H{config.H}_W{config.W}_CI{config.CI}_CO{config.CO}_P{config.P}.hpp\"\n",
    "    filepath = output_dir / filename\n",
    "    header_content = generate_header_file(config, pe_simd_configs, weights_path=weights_file)\n",
    "    \n",
    "\n",
    "    # Write to file\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(header_content)\n",
    "    \n",
    "    generated_files.append({\n",
    "        'filename': filename,\n",
    "        'config': str(config),\n",
    "        'pe_simd_configs': pe_simd_configs,\n",
    "        'filepath': str(filepath)\n",
    "    })\n",
    "    \n",
    "    print(f\"Generated: {filename}\")\n",
    "\n",
    "\n",
    "    # Create a selector header that includes one of the generated config headers\n",
    "    selector_path = output_dir / \"deconv_top.hpp\"\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"// Auto-generated selector header for deconvolution configurations\")\n",
    "    lines.append(\"// Usage: define one of the following macros before including this file:\")\n",
    "    for idx, info in enumerate(generated_files):\n",
    "        param_tag = info['filename'].replace(\"deconv_top_\", \"\").replace(\".hpp\", \"\")\n",
    "        lines.append(f\"//   - DECONV_CFG_IDX_{idx}\")\n",
    "        lines.append(f\"//   - DECONV_CFG_{param_tag}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    guard = \"DECONV_TOP_SELECTOR_HPP\"\n",
    "    lines.append(f\"#ifndef {guard}\")\n",
    "    lines.append(f\"#define {guard}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    if generated_files:\n",
    "        for idx, info in enumerate(generated_files):\n",
    "            param_tag = info['filename'].replace(\"deconv_top_\", \"\").replace(\".hpp\", \"\")\n",
    "            macro_idx = f\"DECONV_CFG_IDX_{idx}\"\n",
    "            macro_param = f\"DECONV_CFG_{param_tag}\"\n",
    "            cond = f\"defined({macro_idx}) || defined({macro_param})\"\n",
    "            prefix = \"#if\" if idx == 0 else \"#elif\"\n",
    "            lines.append(f\"{prefix} {cond}\")\n",
    "            lines.append(f'#include \"{info[\"filename\"]}\"')\n",
    "        # Default to the first config if none specified\n",
    "        lines.append(\"#else\")\n",
    "        lines.append(f'#include \"{generated_files[0][\"filename\"]}\"')\n",
    "        lines.append(\"#endif\")\n",
    "    else:\n",
    "        lines.append('#error \"No configuration headers were generated. Please generate configurations first.\"')\n",
    "\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"#endif // {guard}\")\n",
    "\n",
    "    with open(selector_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(f\"Selector header generated: {selector_path}\")\n",
    "\n",
    "print(f\"\\\\nüìÅ All files saved to: {output_dir.absolute()}\")\n",
    "print(f\"üìä Total files generated: {len(generated_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0dc434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n================================================================================\n",
      "GENERATED CONFIGURATIONS SUMMARY\n",
      "================================================================================\n",
      "Filename                                      Parameters                          PE/SIMD\n",
      "--------------------------------------------------------------------------------\n",
      "deconv_top_K3_S1_H5_W5_CI1_CO3_P2.hpp         K=3, S=1, H=5, W=5, CI=1, CO=3, P=2 (1,1), (3,1)\n",
      "deconv_top_K3_S1_H5_W5_CI1_CO3_P1.hpp         K=3, S=1, H=5, W=5, CI=1, CO=3, P=1 (1,1), (3,1)\n",
      "================================================================================\n",
      "\\nüîß Next Steps:\n",
      "  1. Run HLS project generation: ./manage_hls_projects.sh generate\n",
      "  2. Run C simulation: ./manage_hls_projects.sh csim\n",
      "  3. Run synthesis: ./manage_hls_projects.sh synthesize\n",
      "  4. Run co-simulation: ./manage_hls_projects.sh cosim\n",
      "  5. Gather output files: ./manage_hls_projects.sh gather-outputs\n",
      "  6. Copy golden reference files: ./manage_hls_projects.sh gather-golden\n",
      "  7. Compare results with golden references: ./manage_hls_projects.sh compare-results\n",
      "\\nüìÅ Scripts are organized in the 'scripts/' folder\n",
      "üìÅ Generated configs are in the 'generated_configs/' folder\n",
      "üìÅ All configurations now include padding parameter (P) in filename\n"
     ]
    }
   ],
   "source": [
    "# Display summary table\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "print(\"GENERATED CONFIGURATIONS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Filename':<45} {'Parameters':<35} {'PE/SIMD'}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for file_info in generated_files:\n",
    "    pe_simd_str = \", \".join([f\"({pe},{simd})\" for pe, simd in file_info['pe_simd_configs']])\n",
    "    print(f\"{file_info['filename']:<45} {file_info['config']:<35} {pe_simd_str}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"\\\\nüîß Next Steps:\")\n",
    "print(\"  1. Run HLS project generation: ./manage_hls_projects.sh generate\")\n",
    "print(\"  2. Run C simulation: ./manage_hls_projects.sh csim\")\n",
    "print(\"  3. Run synthesis: ./manage_hls_projects.sh synthesize\")\n",
    "print(\"  4. Run co-simulation: ./manage_hls_projects.sh cosim\")\n",
    "print(\"  5. Gather output files: ./manage_hls_projects.sh gather-outputs\")\n",
    "print(\"  6. Copy golden reference files: ./manage_hls_projects.sh gather-golden\")\n",
    "print(\"  7. Compare results with golden references: ./manage_hls_projects.sh compare-results\")\n",
    "print(\"\\\\nüìÅ Scripts are organized in the 'scripts/' folder\")\n",
    "print(\"üìÅ Generated configs are in the 'generated_configs/' folder\")\n",
    "print(\"üìÅ All configurations now include padding parameter (P) in filename\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2777db",
   "metadata": {},
   "source": [
    "## üîß Next Steps: Complete HLS Workflow with Golden Results Validation\n",
    "\n",
    "After generating the configuration files, follow this workflow:\n",
    "\n",
    "### 1. **Project Organization** \n",
    "All automation scripts are now organized in the `scripts/` folder:\n",
    "- `scripts/validate_hls_setup.tcl` - Environment validation\n",
    "- `scripts/generate_hls_projects.tcl` - Project generation  \n",
    "- `scripts/demo_hls_projects.tcl` - Demonstration workflow\n",
    "- `scripts/test_hls_basic.tcl` - Basic testing\n",
    "\n",
    "### 2. **HLS Development Workflow**\n",
    "```bash\n",
    "# 1. Validate HLS environment\n",
    "./manage_hls_projects.sh validate\n",
    "\n",
    "# 2. Generate HLS projects for all configurations\n",
    "./manage_hls_projects.sh generate\n",
    "\n",
    "# 3. Run complete workflow (C simulation ‚Üí Synthesis ‚Üí Co-simulation)\n",
    "./manage_hls_projects.sh demo\n",
    "\n",
    "# 4. Check project status\n",
    "./manage_hls_projects.sh status\n",
    "```\n",
    "\n",
    "### 3. **Results Collection and Validation**\n",
    "```bash\n",
    "# 5. Gather HLS simulation output files with PE/SIMD naming\n",
    "./manage_hls_projects.sh gather-outputs\n",
    "\n",
    "# 6. Copy golden reference files from experimental data\n",
    "./manage_hls_projects.sh gather-golden\n",
    "\n",
    "# 7. Compare HLS outputs against golden references\n",
    "./manage_hls_projects.sh compare-results\n",
    "```\n",
    "\n",
    "### 4. **Results Analysis**\n",
    "The comparison generates:\n",
    "- **Detailed Report**: `comparison_results/comparison_report.txt` - Line-by-line comparison details\n",
    "- **CSV Summary**: `comparison_results/comparison_summary.csv` - Structured comparison results\n",
    "- **Success Metrics**: Overall pass/fail rates and configuration-specific results\n",
    "\n",
    "### 5. **Directory Structure**\n",
    "```\n",
    "üìÅ Project Structure:\n",
    "‚îú‚îÄ‚îÄ manage_hls_projects.sh          # Main automation script\n",
    "‚îú‚îÄ‚îÄ deconv_generator.ipynb          # This configuration generator\n",
    "‚îú‚îÄ‚îÄ scripts/                        # HLS automation scripts\n",
    "‚îú‚îÄ‚îÄ generated_configs/              # Generated .hpp files\n",
    "‚îú‚îÄ‚îÄ outputs/                        # HLS simulation results (PE/SIMD named)\n",
    "‚îú‚îÄ‚îÄ golden_results/                 # Golden reference files\n",
    "‚îú‚îÄ‚îÄ comparison_results/             # Validation reports\n",
    "‚îî‚îÄ‚îÄ hls_projects/                   # Generated HLS projects\n",
    "```\n",
    "\n",
    "### 6. **Additional Commands**\n",
    "```bash\n",
    "# Individual operations\n",
    "./manage_hls_projects.sh csim        # C simulation only\n",
    "./manage_hls_projects.sh synth       # Synthesis only  \n",
    "./manage_hls_projects.sh cosim       # Co-simulation only\n",
    "./manage_hls_projects.sh clean       # Clean all projects\n",
    "./manage_hls_projects.sh list        # List configurations\n",
    "./manage_hls_projects.sh help        # Show help\n",
    "```\n",
    "\n",
    "**üéØ The workflow ensures synthesis completes before co-simulation and provides comprehensive validation against golden reference data.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeConv_benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
